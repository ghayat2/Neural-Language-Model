## Project 1: Language Modeling with Recurrent Neural Networks in Tensorflow and Continuation of Sentences


## Specs
* Python version 3.6
* Tensorflow 1.12

## Authors
- Gabriel Hayat
- Arthur Deschamps
- Hidde Lycklama Ã  Nijeholt
- Yiji He 

Data was provided by NLU teaching staff. We expect all data (sentences.train, sentences.test.txt, sentences.eval, sentences.continuation, wordembeddings-dim100.word2ve) to be in ./data folder, where current folder contains *.py scripts files

 ## Part 1
 Our task was to build a simple LSTM language model. We could use the tensorflow cell implementation to carry out the recurrent computation but we had to construct the actual RNN ourselves. That means, we needed to use a python loop that sets up the unrolled graph. 
 
### Running the code
#### Generate a vocabulary
To generate a vocabulary, run the command:

`python3 model.py sentences.train`

This will preprocess training data (splitting sentences in words; adding `<bos>`, `<eos>`, `<unk>` and `<pad>` tokens; removing sentences longer than 28 words) 
#### Training the model
To train the RNN, run:

`python3 train.py X`

where X = {A, B, C}, depending on the experiment you want to train the model on.

This will save checkpoint_files in the ./runs/ directory at a certain frequency. You will need this directory in order to evaluate your model
#### Evaluating the model
The model is evaluated using the perplexity scale. To evaluate the model, run the command:

`python3 evaluate.py X <checkpoint_dir>`

where where X = {A, B, C} is the name of the experiment and `<checkpoint_dir>` is the name of the directory generated by training the model.

This will generate a file `group19perplexityX` that will contain the perplexity of every sentence of the file `sentences_test.txt`.

 ## Part 2
We used our trained language model from Part 1 to generate sentences. Given an initial sequence of words, we greedily generate words until either our model decides to finish the sentence (it generated <eos>) or a given maximum length has been reached. 
  
### Running the Code:
To complete the sentences in the file `sentences.continuation`, run the following command:

`python3 finish.py <checkpoint_dir>`

where `<checkpoint_dir>` is the name of the directory generated by training the model.

This will generate a file `group19.continuation` containing sentences of  `sentences.continuation` generated by your model trained by experiment C.
